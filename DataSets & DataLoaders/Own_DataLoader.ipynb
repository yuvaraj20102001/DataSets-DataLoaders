{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import _utils\n",
    "from torch.utils.data import DataLoader,Dataset,default_collate,RandomSampler,SequentialSampler,BatchSampler,Sampler\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(TempDataset, self).__init__()\n",
    "        pass\n",
    "    def __getitem__(self,index):\n",
    "        # print(\"getitem is called\",index)\n",
    "        return index*10\n",
    "    def __len__(self):\n",
    "        len=50\n",
    "        # print(\"len is called \",len)\n",
    "        return len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TempDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Own_Random_sampler():\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset = dataset\n",
    "    def __iter__(self):\n",
    "        list_indices=list(range(len(self.dataset)))\n",
    "        # print(list_indices)\n",
    "        random.shuffle(list_indices)\n",
    "        return iter(list_indices)\n",
    "    def __len__(self):\n",
    "        return len(dataset)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Own_Sequential_sampler():\n",
    "    def __init__(self,dataset):\n",
    "        self.dataset=dataset\n",
    "    def __iter__(self):\n",
    "        return iter(range(len(self.dataset)))\n",
    "    def __len__(self):\n",
    "        return len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Own_batch_sampler():\n",
    "    def __init__(self,dataset=None,sampler=None,drop_last=0,batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.drop_last = drop_last\n",
    "        self.batch_size = batch_size\n",
    "        self.sampler = sampler\n",
    "        \n",
    "    def __iter__(self):\n",
    "        obj=iter(self.sampler)\n",
    "        n=len(self.dataset)\n",
    "        count=0\n",
    "\n",
    "        global batched_indices\n",
    "        batched_indices=[]\n",
    "        \n",
    "\n",
    "        for i in range(n//self.batch_size):\n",
    "            batch=[]\n",
    "            for i in range(self.batch_size):\n",
    "                batch.append(dataset[next(obj)])\n",
    "            count+=1\n",
    "            batched_indices.append(batch)\n",
    "            # print(batched_indices)\n",
    "\n",
    "        if not self.drop_last:\n",
    "            batch=[]\n",
    "            for i in range(n-count*self.batch_size):\n",
    "                batch.append(dataset[next(obj)])\n",
    "            # print(batch)\n",
    "            if len(batch)!=0:\n",
    "                batched_indices.append(batch)\n",
    "        return iter(batched_indices)\n",
    "    def __len__(self):\n",
    "        return len(batched_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OwnDataLoader:\n",
    "    def __init__(self,dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "           batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "           pin_memory=False, drop_last=False, timeout=0,\n",
    "           worker_init_fn=None, *, prefetch_factor=2,\n",
    "           persistent_workers=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.sampler= sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.drop_last = drop_last \n",
    "        # self.collate =  _utils.collate.default_collate\n",
    "\n",
    "        \n",
    "    \n",
    "    def __iter__(self):\n",
    "        \n",
    "            \n",
    "        if self.sampler:\n",
    "            print(\"**\")\n",
    "            # s=self.sampler()\n",
    "            # print(batches)\n",
    "            if self.batch_size:\n",
    "                batches=Own_batch_sampler(self.dataset,self.sampler,self.drop_last,self.batch_size)\n",
    "                # batches=batch_sampler(self.dataset,self.sampler,self.drop_last,self.batch_size)\n",
    "                return iter(batches)\n",
    "            # if self.batch_size==1:\n",
    "\n",
    "            \n",
    "        if self.shuffle:\n",
    "            # rand_obj =Own_Random_sampler(self.dataset)\n",
    "            # batches=Own_batch_sampler(self.dataset,rand_obj,self.drop_last,self.batch_size)\n",
    "            print(\"***\")\n",
    "            # print(batches)\n",
    "            if self.batch_size:\n",
    "                samp=Own_Random_sampler(self.dataset)\n",
    "                batches=Own_batch_sampler(self.dataset,sampler=samp,drop_last=self.drop_last,batch_size=self.batch_size)\n",
    "            return iter(batches)\n",
    "            # return iter(list(range(0,len(self.dataset))))\n",
    "        \n",
    "        # if self.batch_size==1 and not self.sampler and not self.shuffle:\n",
    "        #     samp=Own_Sequential_sampler(dataset)\n",
    "\n",
    "        \n",
    "\n",
    "        if (self.batch_size>1)or(self.batch_size==1 and not self.sampler and not self.shuffle and not self.batch_sampler):\n",
    "            print(\"*\")\n",
    "            samp=Own_Sequential_sampler(dataset)\n",
    "            batches=Own_batch_sampler(self.dataset,samp,self.drop_last,self.batch_size)\n",
    "            return iter(batches)\n",
    "\n",
    "        \n",
    "        \n",
    "        # if self.drop_last and self.batch_size==1:\n",
    "        #     print(\"****\")\n",
    "        #     Rsamp=Own_Random_sampler(self.dataset)\n",
    "        #     Ssamp=Own_Sequential_sampler(self.dataset)\n",
    "\n",
    "        #     if not self.shuffle or self.sampler==None:\n",
    "                \n",
    "        #         batches=Own_batch_sampler(self.dataset,sampler=Ssamp,drop_last=self.drop_last,batch_size=self.batch_size)\n",
    "\n",
    "        #     if self.shuffle or self.sampler != None:\n",
    "        #         batches=Own_batch_sampler(self.dataset,sampler=Rsamp,drop_last=self.drop_last,batch_size=self.batch_size)\n",
    "            \n",
    "        #     return iter(batches)\n",
    "\n",
    "        if self.batch_sampler:\n",
    "            # for i in self.batch_sampler:\n",
    "            #     print(i)\n",
    "            if self.sampler is None and self.shuffle is False and self.batch_size==1:\n",
    "                batches=iter(self.batch_sampler)\n",
    "                return(batches)\n",
    "            else :\n",
    "                print(\"Sampler,Batch size ,shuffle is exclusive of Batch Sampler.\")\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10, 20, 30, 40, 50, 60, 70]\n",
      "[80, 90, 100, 110, 120, 130, 140, 150]\n",
      "[160, 170, 180, 190, 200, 210, 220, 230]\n",
      "[240, 250, 260, 270, 280, 290, 300, 310]\n",
      "[320, 330, 340, 350, 360, 370, 380, 390]\n",
      "[400, 410, 420, 430, 440, 450, 460, 470]\n",
      "[480, 490]\n"
     ]
    }
   ],
   "source": [
    "random_sampler=Own_Random_sampler(dataset)\n",
    "sequential_sampler=Own_Sequential_sampler(dataset)\n",
    "\n",
    "batch_sampler=Own_batch_sampler(dataset,sequential_sampler,0,8)\n",
    "for i in batch_sampler:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_func(batch):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 330 270 400 410 320 80 210 460 250 70 170 430 350 280 340 290 380 10 300 20 90 390 0 60 260 160 470 30 490 40 230 180 50 440 190 450 110 220 310 420 200 360 240 370 140 100 150 480 120 "
     ]
    }
   ],
   "source": [
    "random_sampler=Own_Random_sampler(dataset)\n",
    "for i in random_sampler:\n",
    "    print(dataset[i],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 "
     ]
    }
   ],
   "source": [
    "random_sampler=Own_Sequential_sampler(dataset)\n",
    "for i in random_sampler:\n",
    "    print(dataset[i],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 470 480 490 "
     ]
    }
   ],
   "source": [
    "seq_sampler=Own_Sequential_sampler(dataset)\n",
    "for i in seq_sampler:\n",
    "    print(dataset[i],end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OwnSeq_Sampler():\n",
    "#     def __init__(dataset):\n",
    "#         self.dataset = dataset\n",
    "#     def __iter__():\n",
    "#         return list(random.randint())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "*\n",
      "[0]\n",
      "[10]\n",
      "[20]\n",
      "[30]\n",
      "[40]\n",
      "[50]\n",
      "[60]\n",
      "[70]\n",
      "[80]\n",
      "[90]\n",
      "[100]\n",
      "[110]\n",
      "[120]\n",
      "[130]\n",
      "[140]\n",
      "[150]\n",
      "[160]\n",
      "[170]\n",
      "[180]\n",
      "[190]\n",
      "[200]\n",
      "[210]\n",
      "[220]\n",
      "[230]\n",
      "[240]\n",
      "[250]\n",
      "[260]\n",
      "[270]\n",
      "[280]\n",
      "[290]\n",
      "[300]\n",
      "[310]\n",
      "[320]\n",
      "[330]\n",
      "[340]\n",
      "[350]\n",
      "[360]\n",
      "[370]\n",
      "[380]\n",
      "[390]\n",
      "[400]\n",
      "[410]\n",
      "[420]\n",
      "[430]\n",
      "[440]\n",
      "[450]\n",
      "[460]\n",
      "[470]\n",
      "[480]\n",
      "[490]\n"
     ]
    }
   ],
   "source": [
    "seq_sampler=Own_Sequential_sampler(dataset)\n",
    "random_sampler=Own_Random_sampler(dataset)\n",
    "\n",
    "# dataloader=OwnDataLoader(dataset,batch_size=3,sampler=seq_sampler,drop_last=1)\n",
    "# dataloader=OwnDataLoader(dataset,sampler=random_sampler,batch_size=3,drop_last=1)\n",
    "dataloader=OwnDataLoader(dataset,shuffle=True,batch_size=3,drop_last=1)\n",
    "# dataloader=OwnDataLoader(dataset,batch_size=3)\n",
    "# dataloader=OwnDataLoader(dataset,sampler=random_sampler,batch_size=3)\n",
    "dataloader=OwnDataLoader(dataset)\n",
    "# dataloader=OwnDataLoader(dataset,sampler=random_sampler,drop_last=False)\n",
    "\n",
    "\n",
    "\n",
    "# batch_sampler=Own_batch_sampler(dataset=dataset,sampler=random_sampler,drop_last=True,batch_size=3)\n",
    "\n",
    "# dataloader=OwnDataLoader(dataset,batch_sampler=batch_sampler)\n",
    "\n",
    "print(len(dataloader))\n",
    "# print(dataloader[i])\n",
    "for i in dataloader:\n",
    "    print(i)\n",
    "    # print(i,end=\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# batch_sampler=Own_batch_sampler(dataset=dataset,sampler=random_sampler,drop_last=False,batch_size=2)\n",
    "# dataloader=OwnDataLoader(dataset,batch_sampler=batch_sampler)\n",
    "# for x,y in dataloader:\n",
    "#     print(x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
